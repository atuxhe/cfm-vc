{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "f0_predictor = utils.get_f0_predictor(\n",
    "    \"fcpe\",\n",
    "    sampling_rate=22050,\n",
    "    hop_length=256,\n",
    "    device=\"cpu\",\n",
    "    threshold=0.05,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Load the model\n",
    "model = torch.load(\"pretrain/fcpe_c_v001.pt\", map_location=\"cpu\")\n",
    "model.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.cfm.dit import DiT\n",
    "import torch\n",
    "\n",
    "dit = DiT(\n",
    "    in_channels=100 * 2,\n",
    "    hidden_channels=256,\n",
    "    out_channels=100,\n",
    "    filter_channels=256 * 4,\n",
    "    dropout=0.05,\n",
    "    n_layers=4,\n",
    "    n_heads=4,\n",
    "    kernel_size=3,\n",
    "    utt_emb_dim=512,\n",
    ")\n",
    "\n",
    "# print dit parameter count\n",
    "print(f\"DiT parameter count: {sum(p.numel() for p in dit.parameters())}\")\n",
    "\n",
    "x = torch.randn(1, 100, 128)\n",
    "x_mask = torch.ones(1, 1, 128)\n",
    "mu = torch.randn(1, 100, 128)\n",
    "t = torch.Tensor([0.2])\n",
    "spks = torch.randn(1, 512)\n",
    "cond = torch.randn(1, 192, 32)\n",
    "cond_mask = torch.ones(1, 1, 32)\n",
    "\n",
    "dit(x, x_mask, mu, t, spks, cond, cond_mask).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DiT\n",
      "VC model parameter count: 51650217\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVC model parameter count: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(p\u001b[38;5;241m.\u001b[39mnumel()\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mp\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mvc_model\u001b[38;5;241m.\u001b[39mparameters())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# (prior_loss, diff_loss, f0_pred, lf0)\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m \u001b[43mvc_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mppgs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mppgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_lengths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc_lengths\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from models import SynthesizerTrn\n",
    "\n",
    "vc_model = SynthesizerTrn(\n",
    "    spec_channels=128,\n",
    "    hidden_channels=192,\n",
    "    filter_channels=768,\n",
    "    n_heads=2,\n",
    "    n_layers=6,\n",
    "    kernel_size=3,\n",
    "    p_dropout=0.1,\n",
    "    speaker_embedding=512,\n",
    "    n_speakers=10,\n",
    "    ssl_dim=768,\n",
    "    ppgs_dim=40,\n",
    ")\n",
    "\n",
    "c = torch.randn(1, 768, 56)\n",
    "c_lengths = torch.Tensor([56])\n",
    "ppgs = torch.randn(1, 40, 56)\n",
    "spec = torch.randn(1, 128, 56)\n",
    "f0 = torch.randn(1, 1, 56)\n",
    "uv = torch.ones(1, 56)\n",
    "g = torch.randn(1, 512)\n",
    "\n",
    "\n",
    "# print dit parameter count\n",
    "print(f\"VC model parameter count: {sum(p.numel() for p in vc_model.parameters())}\")\n",
    "\n",
    "# (prior_loss, diff_loss, f0_pred, lf0)\n",
    "vc_model(c=c, f0=f0, uv=uv, spec=spec, ppgs=ppgs, c_lengths=c_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond, cond_mask, g = vc_model.compute_conditional_latent([spec], [c_lengths])\n",
    "g.shape, cond.shape, cond_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deocder_output, _ = vc_model.infer(c=c, f0=f0, uv=uv, spec=spec, ppgs=ppgs)\n",
    "deocder_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "def temporal_avg_pool(x, mask=None):\n",
    "\n",
    "    len_ = mask.sum(dim=-1)\n",
    "    return torch.sum(x * mask, dim=-1) / len_\n",
    "\n",
    "latents = torch.randn(1, 192, 32)\n",
    "latents_mask = torch.ones(1, 1, 32)\n",
    "\n",
    "meanpooled_latents = temporal_avg_pool(latents, latents_mask)\n",
    "meanpooled_latents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ppgs\n",
    "from glob import glob\n",
    "\n",
    "wavs_paths = glob(\"/home/alex/Projekte/TestData/Extended/Dexter/**/*.wav\", recursive=True)\n",
    "ppgs_paths = [path.replace(\".wav\", \".ppg.pt\") for path in wavs_paths]\n",
    "\n",
    "ppgs.from_files_to_files(wavs_paths, ppgs_paths, gpu=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "wavs_paths = glob(\"/home/alex/Projekte/TestData/Extended/Dexter/**/*.wav\", recursive=True)\n",
    "\n",
    "with open(\"/home/alex/Projekte/so-vits-svc/filelists/gametts_train.txt\", \"w\") as f:\n",
    "    for path in wavs_paths:\n",
    "        f.write(f\"{path}|0\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
