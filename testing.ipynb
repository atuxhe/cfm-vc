{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "f0_predictor = utils.get_f0_predictor(\n",
    "    \"fcpe\",\n",
    "    sampling_rate=22050,\n",
    "    hop_length=256,\n",
    "    device=\"cpu\",\n",
    "    threshold=0.05,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Load the model\n",
    "model = torch.load(\"/workspace/pretrained_models/fcpe_c_v001.pt\", map_location=\"cpu\")\n",
    "model.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.cfm.dit import DiT\n",
    "import torch\n",
    "\n",
    "dit = DiT(\n",
    "    in_channels=80 * 2,\n",
    "    hidden_channels=192,\n",
    "    out_channels=80,\n",
    "    filter_channels=192 * 4,\n",
    "    dropout=0.05,\n",
    "    n_layers=6,\n",
    "    n_heads=2,\n",
    "    kernel_size=3,\n",
    "    utt_emb_dim=512,\n",
    ")\n",
    "\n",
    "# print dit parameter count\n",
    "print(f\"DiT parameter count: {sum(p.numel() for p in dit.parameters())}\")\n",
    "\n",
    "x = torch.randn(1, 80, 128)\n",
    "x_mask = torch.ones(1, 1, 128)\n",
    "mu = torch.randn(1, 80, 128)\n",
    "t = torch.Tensor([0.2])\n",
    "spks = torch.randn(1, 512)\n",
    "cond = torch.randn(1, 192, 32)\n",
    "cond_mask = torch.ones(1, 1, 32)\n",
    "\n",
    "dit(x, x_mask, mu, t, spks, cond, cond_mask).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models import SynthesizerTrn\n",
    "\n",
    "vc_model = SynthesizerTrn(\n",
    "    spec_channels=80,\n",
    "    hidden_channels=192,\n",
    "    filter_channels=768,\n",
    "    n_heads=2,\n",
    "    n_layers=6,\n",
    "    kernel_size=3,\n",
    "    p_dropout=0.1,\n",
    "    speaker_embedding=512,\n",
    "    n_speakers=10,\n",
    "    ssl_dim=768,\n",
    "    ppgs_dim=40,\n",
    ")\n",
    "\n",
    "c = torch.randn(1, 768, 56)\n",
    "c_lengths = torch.Tensor([56])\n",
    "ppgs = torch.randn(1, 40, 56)\n",
    "spec = torch.randn(1, 80, 56)\n",
    "f0 = torch.randn(1, 1, 56)\n",
    "uv = torch.ones(1, 56)\n",
    "g = torch.randn(1, 512)\n",
    "\n",
    "\n",
    "# print dit parameter count\n",
    "print(f\"VC model parameter count: {sum(p.numel() for p in vc_model.parameters())}\")\n",
    "\n",
    "# (prior_loss, diff_loss, f0_pred, lf0)\n",
    "vc_model(c=c, f0=f0, uv=uv, spec=spec, ppgs=ppgs, c_lengths=c_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc_model.decoder.estimator.blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond, cond_mask, g = vc_model.compute_conditional_latent([spec], [c_lengths])\n",
    "g.shape, cond.shape, cond_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deocder_output, _ = vc_model.infer(c=c, f0=f0, uv=uv, spec=spec, ppgs=ppgs)\n",
    "deocder_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.perceiver_encoder import PerceiverResampler\n",
    "import torch\n",
    "\n",
    "\n",
    "resampler = PerceiverResampler(\n",
    "    hidden_channels=192,\n",
    "    depth=2,\n",
    "    num_latents=32,\n",
    "    dim_head=64,\n",
    "    heads=8,\n",
    "    ff_mult=4,\n",
    ")\n",
    "\n",
    "spec = torch.randn(1, 192, 56)\n",
    "spec_mask = torch.ones(1, 1, 56)\n",
    "\n",
    "\n",
    "resampler(spec, spec_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "train_all = [\n",
    "    \"/workspace/metadata/filelists/xphoneBERT/en_borderlands2_xphone.csv\",\n",
    "    \"/workspace/metadata/filelists/xphoneBERT/en_baldursgate3_xphone.csv\",\n",
    "    \"/workspace/metadata/filelists/xphoneBERT/en_worldofwarcraft_xphone.csv\",\n",
    "    \"/workspace/metadata/filelists/xphoneBERT/en_mario_xphone.csv\",\n",
    "    \"/workspace/metadata/filelists/xphoneBERT/de_gametts_xphone.csv\",\n",
    "    \"/workspace/metadata/filelists/xphoneBERT/pl_archolos_xphone.csv\",\n",
    "    \"/workspace/metadata/filelists/xphoneBERT/de_borderlands2_xphone.csv\",\n",
    "    \"/workspace/metadata/filelists/xphoneBERT/en_warcraft_xphone.csv\",\n",
    "    \"/workspace/metadata/filelists/xphoneBERT/en_sqnarrator_xphone.csv\",\n",
    "    \"/workspace/metadata/filelists/xphoneBERT/en_emotional_train_xphone.csv\",\n",
    "    \"/workspace/metadata/filelists/xphoneBERT/de_emotional_train_xphone.csv\",\n",
    "    \"/workspace/metadata/filelists/xphoneBERT/ru_witcher3_xphone.csv\",\n",
    "    \"/workspace/metadata/filelists/xphoneBERT/en_witcher3_skyrim_xphone.csv\",\n",
    "    \"/workspace/metadata/filelists/xphoneBERT/en_fallout4_xphone.csv\",\n",
    "    \"/workspace/metadata/filelists/xphoneBERT/en_naruto_xphone.csv\",\n",
    "    \"/workspace/metadata/filelists/xphoneBERT/de_kcd_xphone.csv\",\n",
    "    \"/workspace/metadata/filelists/xphoneBERT/pl_witcher3_xphone.csv\",\n",
    "    \"/workspace/metadata/filelists/xphoneBERT/de_diablo4_xphone.csv\",\n",
    "    \"/workspace/metadata/filelists/xphoneBERT/en_diablo4_xphone.csv\",\n",
    "    \"/workspace/metadata/filelists/xphoneBERT/fr_diablo4_xphone.csv\",\n",
    "    \"/workspace/metadata/filelists/xphoneBERT/pl_diablo4_xphone.csv\",\n",
    "    \"/workspace/metadata/filelists/xphoneBERT/ru_diablo4_xphone.csv\",\n",
    "    \"/workspace/metadata/filelists/xphoneBERT/ru_skyrim_xphone.csv\",\n",
    "    # \"/workspace/metadata/filelists/xphoneBERT/jp_one_piece_xphone.csv\",\n",
    "    # \"/workspace/metadata/filelists/xphoneBERT/jp_skyrim_xphone.csv\",\n",
    "    # \"/workspace/dataset/fr/Fallout4/fr_fallout4_xphone.csv\",\n",
    "    # \"/workspace/dataset/de/Fallout4/de_fallout4_xphone.csv\",\n",
    "    # \"/workspace/dataset/en/Fallout4/en_fallout4_xphone.csv\",\n",
    "]\n",
    "\n",
    "all_lines = []\n",
    "\n",
    "for file in train_all:\n",
    "    with open(file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        all_lines.extend(lines)\n",
    "\n",
    "random.shuffle(all_lines)\n",
    "\n",
    "files_max_per_speaker = 50\n",
    "min_audio_length = 0.3 * 22050\n",
    "max_audio_length = 12.0 * 22050\n",
    "\n",
    "speaker_files_dict = {}\n",
    "\n",
    "with open(\"/workspace/tts_train_slim.csv\", \"w\") as wf:\n",
    "    for line in all_lines:\n",
    "        cols = line.split(\"|\")\n",
    "        filename = cols[0]\n",
    "        speaker = cols[1]\n",
    "        emotion = cols[2]\n",
    "        language = cols[3]\n",
    "        text = cols[-2]\n",
    "        text_orig = cols[-1]\n",
    "\n",
    "        filename = filename.replace(\"/mnt/datasets/TTS_Data\", \"/workspace/dataset\")\n",
    "\n",
    "        if any(\n",
    "            v in text_orig\n",
    "            for v in [\"v1\", \"v2\", \"v3\", \"v4\", \"v5\", \"v6\", \"v7\", \"v8\", \"v9\", \"v10\"]\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        if not Path(filename).exists():\n",
    "            continue\n",
    "\n",
    "        if max_audio_length < Path(filename).stat().st_size // 2 < min_audio_length:\n",
    "            continue\n",
    "\n",
    "        if any(char in \"#[]{}*\" for char in text_orig):\n",
    "            continue\n",
    "\n",
    "        # if len(text) < 4 or len(text) > 350:\n",
    "        #     continue\n",
    "\n",
    "        if speaker not in speaker_files_dict:\n",
    "            speaker_files_dict[speaker] = []\n",
    "            speaker_files_dict[speaker].append(line)\n",
    "            wf.write(f\"{filename}|{speaker}|{language}|{text_orig}\")\n",
    "        else:\n",
    "            if len(speaker_files_dict[speaker]) < files_max_per_speaker:\n",
    "                speaker_files_dict[speaker].append(line)\n",
    "                wf.write(f\"{filename}|{speaker}|{language}|{text_orig}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ppgs\n",
    "\n",
    "print(ppgs.MAX_INFERENCE_FRAMES)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
