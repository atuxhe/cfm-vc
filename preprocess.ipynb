{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from random import shuffle\n",
    "\n",
    "from loguru import logger\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "min_duration = 22050 * 2.0\n",
    "max_duration = 22050 * 10.0\n",
    "\n",
    "config_template = json.load(open(\"configs_template/config_template.json\"))\n",
    "\n",
    "training_files = [\n",
    "      \"/mnt/datasets/TTS_Data/metadata/filelists/xphoneBERT/en_borderlands2_xphone.csv\",\n",
    "      \"/mnt/datasets/TTS_Data/metadata/filelists/xphoneBERT/en_baldursgate3_xphone.csv\",\n",
    "      \"/mnt/datasets/TTS_Data/metadata/filelists/xphoneBERT/en_worldofwarcraft_xphone.csv\",\n",
    "      \"/mnt/datasets/TTS_Data/metadata/filelists/xphoneBERT/en_mario_xphone.csv\",\n",
    "      \"/mnt/datasets/TTS_Data/metadata/filelists/xphoneBERT/de_gametts_xphone.csv\",\n",
    "      \"/mnt/datasets/TTS_Data/metadata/filelists/xphoneBERT/pl_archolos_xphone.csv\",\n",
    "      \"/mnt/datasets/TTS_Data/metadata/filelists/xphoneBERT/de_borderlands2_xphone.csv\",\n",
    "      \"/mnt/datasets/TTS_Data/metadata/filelists/xphoneBERT/en_warcraft_xphone.csv\",\n",
    "      \"/mnt/datasets/TTS_Data/metadata/filelists/xphoneBERT/en_sqnarrator_xphone.csv\",\n",
    "      \"/mnt/datasets/TTS_Data/metadata/filelists/xphoneBERT/en_emotional_train_xphone.csv\",\n",
    "      \"/mnt/datasets/TTS_Data/metadata/filelists/xphoneBERT/de_emotional_train_xphone.csv\",\n",
    "      \"/mnt/datasets/TTS_Data/metadata/filelists/xphoneBERT/ru_witcher3_xphone.csv\",\n",
    "      \"/mnt/datasets/TTS_Data/metadata/filelists/xphoneBERT/en_witcher3_skyrim_xphone.csv\",\n",
    "      \"/mnt/datasets/TTS_Data/metadata/filelists/xphoneBERT/en_fallout4_xphone.csv\",\n",
    "      \"/mnt/datasets/TTS_Data/metadata/filelists/xphoneBERT/en_naruto_xphone.csv\",\n",
    "      \"/mnt/datasets/TTS_Data/metadata/filelists/xphoneBERT/de_kcd_xphone.csv\",\n",
    "      \"/mnt/datasets/TTS_Data/metadata/filelists/xphoneBERT/pl_witcher3_xphone.csv\",\n",
    "      \"/mnt/datasets/TTS_Data/metadata/filelists/xphoneBERT/de_diablo4_xphone.csv\",\n",
    "      \"/mnt/datasets/TTS_Data/metadata/filelists/xphoneBERT/en_diablo4_xphone.csv\",\n",
    "      \"/mnt/datasets/TTS_Data/metadata/filelists/xphoneBERT/fr_diablo4_xphone.csv\",\n",
    "      \"/mnt/datasets/TTS_Data/metadata/filelists/xphoneBERT/pl_diablo4_xphone.csv\",\n",
    "      \"/mnt/datasets/TTS_Data/metadata/filelists/xphoneBERT/ru_diablo4_xphone.csv\",\n",
    "      \"/mnt/datasets/TTS_Data/metadata/filelists/xphoneBERT/ru_skyrim_xphone.csv\",\n",
    "      \"/mnt/datasets/TTS_Data/metadata/filelists/xphoneBERT/jp_one_piece_xphone.csv\",\n",
    "      \"/mnt/datasets/TTS_Data/metadata/filelists/xphoneBERT/jp_skyrim_xphone.csv\",\n",
    "      \"/mnt/datasets/TTS_Data/fr/Fallout4/fr_fallout4_xphone.csv\",\n",
    "      \"/mnt/datasets/TTS_Data/de/Fallout4/de_fallout4_xphone.csv\",\n",
    "      \"/mnt/datasets/TTS_Data/en/Fallout4/en_fallout4_xphone.csv\",\n",
    "]\n",
    "\n",
    "all_lines = []\n",
    "\n",
    "for file in training_files:\n",
    "    with open(file) as f:\n",
    "        lines = f.readlines()\n",
    "        all_lines.extend(lines)\n",
    "\n",
    "len(all_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavs = []\n",
    "train = []\n",
    "val = []\n",
    "spk_dict = {}\n",
    "spk_id = 0\n",
    "speaker_items_count = {}\n",
    "duplicate_wavs = set()\n",
    "\n",
    "shuffle(all_lines)\n",
    "\n",
    "for line in tqdm(all_lines):\n",
    "    cols = line.strip().split(\"|\")\n",
    "    speaker_name = cols[1]\n",
    "    wav_path = cols[0]\n",
    "\n",
    "    if not os.path.exists(wav_path):\n",
    "        continue\n",
    "\n",
    "    if not (max_duration >= (Path(wav_path).stat().st_size // 2) > min_duration):\n",
    "        continue\n",
    "\n",
    "    if speaker_name not in spk_dict:\n",
    "        speaker_items_count[speaker_name] = 0\n",
    "        spk_dict[speaker_name] = spk_id\n",
    "        spk_id += 1\n",
    "    else:\n",
    "        speaker_items_count[speaker_name] += 1\n",
    "\n",
    "    if (wav_path, speaker_name) in duplicate_wavs:\n",
    "        continue\n",
    "\n",
    "    if speaker_items_count[speaker_name] < 150:\n",
    "        duplicate_wavs.add(wav_path)\n",
    "        wavs.append((wav_path, speaker_name))\n",
    "\n",
    "shuffle(wavs)\n",
    "\n",
    "with open(\"/home/alexander/Projekte/so-vits-svc/filelists/voice_conversion_train.txt\", \"w\") as f:\n",
    "    for wav_path, speaker_name in wavs:\n",
    "        speaker_id = spk_dict[speaker_name]\n",
    "        f.write(f\"{wav_path}|{speaker_id}\\n\")\n",
    "\n",
    "\n",
    "config_template[\"spk\"] = spk_dict\n",
    "config_template[\"model\"][\"n_speakers\"] = spk_id\n",
    "config_template[\"model\"][\"speech_encoder\"] = \"vec768l12\"\n",
    "\n",
    "\n",
    "logger.info(\"Writing to configs/config_vc.json\")\n",
    "with open(\"configs/config_vc.json\", \"w\") as f:\n",
    "    json.dump(config_template, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from random import shuffle\n",
    "\n",
    "from loguru import logger\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import wave \n",
    "\n",
    "min_duration = 22050 * 1.0\n",
    "max_duration = 22050 * 8.0\n",
    "wavs = []\n",
    "train = []\n",
    "val = []\n",
    "spk_dict = {}\n",
    "spk_id = 6860\n",
    "speaker_items_count = {}\n",
    "duplicate_wavs = set()\n",
    "\n",
    "all_wavs = glob(\"/mnt/datasets/TTS_Data/en/FF7/**/*.wav\", recursive=True)\n",
    "\n",
    "shuffle(all_wavs)\n",
    "\n",
    "for file_path in tqdm(all_wavs):\n",
    "\n",
    "    wav_path = file_path\n",
    "    speaker_name = file_path.split(\"/\")[-2]\n",
    "    \n",
    "    if \"announcer\" in speaker_name:\n",
    "        continue\n",
    "\n",
    "    if not os.path.exists(wav_path):\n",
    "        continue\n",
    "\n",
    "    # Open the WAV file\n",
    "    with wave.open(wav_path, 'r') as wav_file:\n",
    "        # Get the number of frames and the frame rate\n",
    "        frames = wav_file.getnframes()\n",
    "        frame_rate = wav_file.getframerate()\n",
    "\n",
    "        # Calculate the duration in seconds\n",
    "        duration_seconds = frames / float(frame_rate)\n",
    "\n",
    "    if not (8.0 >= duration_seconds > 1.0):\n",
    "        continue\n",
    "\n",
    "    if speaker_name not in spk_dict:\n",
    "        speaker_items_count[speaker_name] = 0\n",
    "        spk_dict[speaker_name] = spk_id\n",
    "        spk_id += 1\n",
    "    else:\n",
    "        speaker_items_count[speaker_name] += 1\n",
    "\n",
    "    if (wav_path, speaker_name) in duplicate_wavs:\n",
    "        continue\n",
    "\n",
    "    if speaker_items_count[speaker_name] < 200:\n",
    "        duplicate_wavs.add(wav_path)\n",
    "        wavs.append((wav_path, speaker_name))\n",
    "\n",
    "shuffle(wavs)\n",
    "\n",
    "with open(\"/home/alexander/Projekte/so-vits-svc/filelists/voice_conversion_train_ff7.txt\", \"w\") as f:\n",
    "    for wav_path, speaker_name in wavs:\n",
    "        speaker_id = spk_dict[speaker_name]\n",
    "        f.write(f\"{wav_path}|{speaker_id}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/alexander/Projekte/so-vits-svc/filelists/voice_conversion_train.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "# get max speaker id\n",
    "max_speaker_id = 0\n",
    "for line in lines:\n",
    "    cols = line.strip().split(\"|\")\n",
    "    wav_path = cols[0]\n",
    "    speaker_id = cols[1]\n",
    "    \n",
    "    if int(speaker_id) > max_speaker_id:\n",
    "        max_speaker_id = int(speaker_id)\n",
    "\n",
    "max_speaker_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess F0 and Hubert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = []\n",
    "for file, speaker in wavs:\n",
    "    file_paths.append(file)\n",
    "\n",
    "print(len(file_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_duplicates(lst):\n",
    "    seen = set()\n",
    "    duplicates = set()\n",
    "\n",
    "    for sublist in lst:\n",
    "        # Convert the list into a tuple to make it hashable\n",
    "        t = tuple(sublist)\n",
    "\n",
    "        if t in seen:\n",
    "            duplicates.add(t)\n",
    "        seen.add(t)\n",
    "\n",
    "    return list(duplicates)\n",
    "\n",
    "\n",
    "dups = find_duplicates(wavs)\n",
    "dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_duped = []\n",
    "with open(\n",
    "    \"/home/alexander/Projekte/so-vits-svc/filelists/voice_conversion_train.txt\", \"r\"\n",
    ") as rf:\n",
    "    for line in rf:\n",
    "        fil = line.strip().split(\"|\")[0]\n",
    "        if not any(fil in dup for dup, speak in dups):\n",
    "            de_duped.append(line)\n",
    "\n",
    "with open(\n",
    "    \"/home/alexander/Projekte/so-vits-svc/filelists/voice_conversion_train.txt\", \"w\"\n",
    ") as wf:\n",
    "    for line in de_duped:\n",
    "        wf.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import librosa\n",
    "import torch\n",
    "import numpy as np\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import torch.multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "\n",
    "sampling_rate = 22050\n",
    "hop_length = 256\n",
    "speech_encoder = \"vec768l12\"\n",
    "device = \"cuda:0\"\n",
    "f0p = \"crepe\"\n",
    "\n",
    "save_path = \"/mnt/datasets/VC_Data\"\n",
    "\n",
    "\n",
    "def process_one(filename, hmodel, f0p, device, diff=False, mel_extractor=None):\n",
    "    filename, speaker = filename\n",
    "    wav, sr = librosa.load(filename, sr=sampling_rate)\n",
    "    audio_norm = torch.FloatTensor(wav)\n",
    "    audio_norm = audio_norm.unsqueeze(0)\n",
    "\n",
    "    # get only the filename without path and without the extension\n",
    "    only_filename = os.path.splitext(os.path.basename(filename))[0]\n",
    "\n",
    "    soft_path = os.path.join(save_path, only_filename + f\"_{speaker}_.soft.pt\")\n",
    "    if not os.path.exists(soft_path):\n",
    "        wav16k = librosa.resample(wav, orig_sr=sampling_rate, target_sr=16000)\n",
    "        wav16k = torch.from_numpy(wav16k).to(device)\n",
    "        c = hmodel.encoder(wav16k)\n",
    "        torch.save(c.cpu(), soft_path)\n",
    "\n",
    "    f0_path = filename.replace(\".wav\", \".pitch.pt\")\n",
    "    if not os.path.exists(f0_path):\n",
    "        f0_predictor = utils.get_f0_predictor(\n",
    "            f0p,\n",
    "            sampling_rate=sampling_rate,\n",
    "            hop_length=hop_length,\n",
    "            device=device,\n",
    "            threshold=0.05,\n",
    "        )\n",
    "\n",
    "        f0, uv = f0_predictor.compute_f0_uv(wav)\n",
    "\n",
    "        # Assuming f0 and uv are numpy arrays\n",
    "        f0_tensor = torch.from_numpy(f0)\n",
    "        uv_tensor = torch.from_numpy(uv)\n",
    "\n",
    "        # Save as a dictionary for clarity\n",
    "        data_to_save = {\"f0\": f0_tensor, \"uv\": uv_tensor}\n",
    "        torch.save(data_to_save, f0_path)\n",
    "\n",
    "        # np.save(f0_path, np.asanyarray((f0, uv), dtype=object))\n",
    "\n",
    "\n",
    "def process_batch(file_chunk, f0p, diff=False, mel_extractor=None, device=\"cpu\"):\n",
    "    logger.info(\"Loading speech encoder for content...\")\n",
    "    rank = mp.current_process()._identity\n",
    "    rank = rank[0] if len(rank) > 0 else 0\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_id = rank % torch.cuda.device_count()\n",
    "        device = torch.device(f\"cuda:{gpu_id}\")\n",
    "    logger.info(f\"Rank {rank} uses device {device}\")\n",
    "    hmodel = utils.get_speech_encoder(speech_encoder, device=device)\n",
    "    logger.info(f\"Loaded speech encoder for rank {rank}\")\n",
    "    for filename in tqdm(file_chunk, position=rank):\n",
    "        process_one(filename, hmodel, f0p, device, diff, mel_extractor)\n",
    "\n",
    "\n",
    "def parallel_process(filenames, num_processes, f0p, diff, mel_extractor, device):\n",
    "    with ProcessPoolExecutor(max_workers=num_processes) as executor:\n",
    "        tasks = []\n",
    "        for i in range(num_processes):\n",
    "            start = int(i * len(filenames) / num_processes)\n",
    "            end = int((i + 1) * len(filenames) / num_processes)\n",
    "            file_chunk = filenames[start:end]\n",
    "            tasks.append(\n",
    "                executor.submit(\n",
    "                    process_batch, file_chunk, f0p, diff, mel_extractor, device=device\n",
    "                )\n",
    "            )\n",
    "        for task in tqdm(tasks, position=0):\n",
    "            task.result()\n",
    "\n",
    "\n",
    "parallel_process(wavs, 7, f0p, False, None, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import wave\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "all_wavs = glob(\"/mnt/datasets/TTS_Data/en/FF7/**/*.wav\", recursive=True)\n",
    "\n",
    "for wav_path in tqdm(all_wavs):\n",
    "    # Open the WAV file\n",
    "    with wave.open(wav_path, 'r') as wav_file:\n",
    "        # Get the number of frames and the frame rate\n",
    "        frames = wav_file.getnframes()\n",
    "        frame_rate = wav_file.getframerate()\n",
    "\n",
    "        # Calculate the duration in seconds\n",
    "        duration_seconds = frames / float(frame_rate)\n",
    "\n",
    "\n",
    "        if not (7.0 >= duration_seconds > 1.0):\n",
    "            os.remove(wav_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
